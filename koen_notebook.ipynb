{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pysocialforce as psf\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define initial state of agents\n",
    "n = 10\n",
    "\n",
    "# Define goal position\n",
    "goal_position = np.array([2, 17.5])\n",
    "goal_position2 = np.array([-10, 7.5])\n",
    "goal_position3 = np.array([10, 7.5])\n",
    "\n",
    "goals = np.array([goal_position, goal_position2, goal_position3])\n",
    "obstacles = [[-10, 0, 15, 15], [2.5, 10, 15, 15], [-5, -5, 7.5, 15], [-5, -5, 5, 0], [5, 5, 7.5, 15], [5, 5, 5, 0], [-5, 5, 0, 0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents that reached the goal: 10\n"
     ]
    }
   ],
   "source": [
    "# Helper function: aligns velocity with goal\n",
    "def initialize_velocity(position, goal):\n",
    "    direction = goal - position\n",
    "    norm = np.linalg.norm(direction)\n",
    "    if norm == 0:\n",
    "        return np.array([0, 0])\n",
    "    return direction / norm  # Unit vector towards the goal\n",
    "\n",
    "# Initialize each agent\n",
    "initial_state = np.array([])\n",
    "agent = []\n",
    "for i in range(n):\n",
    "\tgoal = random.choice(goals)\n",
    "\tx = random.uniform(-5, 5)\n",
    "\ty = random.uniform(0, 15)\n",
    "\tvx = initialize_velocity(np.array([x, y]), goal)[0]\n",
    "\tvy = initialize_velocity(np.array([x, y]), goal)[1]\n",
    "\tagent.append([x, y, vx, vy, goal[0], goal[1]])\n",
    "\n",
    "initial_state = np.array(agent)\n",
    "\n",
    "# Initialize the simulator\n",
    "sim = psf.Simulator(\n",
    "\tinitial_state, groups=None, obstacles=obstacles, config_file=\"loes.toml\"\n",
    ")\n",
    "\n",
    "# Counter for agents that have reached the goal\n",
    "agents_reached_goal = 0\n",
    "agents_already_counted = set()  # Set to track counted agents to avoid double counting since removing agents from the simulator is not yet working\n",
    "\n",
    "# Function to check if an agent has reached the goal\n",
    "def check_reached_goal(agent_position, y_goal=15, x_goal=5, x_goal2=-5):\n",
    "\t# Check if the agent has reached the goal\n",
    "\tif agent_position[1] > y_goal or agent_position[0] > x_goal or agent_position[0] < x_goal2:\n",
    "\t\treturn True\n",
    "\t\t\n",
    "\n",
    "# Perform simulation steps and remove agents that reach the goal \n",
    "for step in range(50):\n",
    "\tsim.step(n=1)\n",
    "\tped_states, group_states = sim.get_states()  # Access the current state of agents\n",
    "\n",
    "\t# Extract the relevant frame (assuming we need the latest frame, index 0 for instance)\n",
    "\tcurrent_state = ped_states[-1]  # Use the last frame for the current state\n",
    "\n",
    "\tnew_ped_states = []\n",
    "\tfor i, agent_state in enumerate(current_state):\n",
    "\t\tagent_position = agent_state[:2]  # Ensure agent_position is an array of shape (2,)\n",
    "\n",
    "\t\tif check_reached_goal(agent_position):\n",
    "\t\t\tif i not in agents_already_counted:\n",
    "\t\t\t\tagents_reached_goal += 1\n",
    "\t\t\t\tagents_already_counted.add(i)\n",
    "\t\telse:\n",
    "\t\t\tnew_ped_states.append(agent_state)\n",
    "\t\n",
    "\t# Update the simulator's state directly with agents that haven't reached the goal\n",
    "\tsim.ped_states = [np.array(new_ped_states)] if new_ped_states else []\n",
    "\n",
    "\tif len(new_ped_states) == 0:\n",
    "\t\tbreak  # Exit the loop if all agents have reached the goal\n",
    "\n",
    "print(f\"Number of agents that reached the goal: {agents_reached_goal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:[plot.py:131            __enter__() ] Start plotting.\n",
      "INFO:[plot.py:162             __exit__() ] Plotting ends.\n",
      "INFO:[plot.py:166             __exit__() ] Saving animation as mult_goals.gif\n",
      "DEBUG:[animation.py:651          isAvailable() ] ImageMagick unavailable due to: [Errno 2] No such file or directory: 'convert'\n",
      "WARNING:[animation.py:1047                 save() ] MovieWriter imagemagick unavailable; using Pillow instead.\n",
      "INFO:[animation.py:1050                 save() ] Animation.save using <class 'matplotlib.animation.PillowWriter'>\n"
     ]
    }
   ],
   "source": [
    "# Visualize the scene\n",
    "with psf.plot.SceneVisualizer(sim, \"mult_goals\") as sv:\n",
    "    sv.animate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
